learning_rate: 0.0003
reward_decay: 0.99
e_greedy: 0.95
replace_target_iter: 300
memory_size: 200000
batch_size: 128
e_greedy_increment: 0.0005
start_greedy: 0.0
output_graph: True
save_model: True
learning_step: 10000
summary_output_times: 10
load_model: False
load_model_path: ''
soft_update: False

#run
reward_memory: 100
save_per_episodes: 2000

# network
n_layer_1: 5
regularizer: 0.001
target_network_decay: 0.001

# output
SAVE_PATH: "model"
graph_path: "graph"
reward_output: "output"
output_filename: "out"
log: "log"