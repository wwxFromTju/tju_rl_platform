#copy dqn
learning_rate_a: 0.0003
learning_rate_c: 0.0003
reward_decay: 0.99
batch_size: 32
output_graph: True
save_model: True
summary_output_times: 10
clip_value: 0.2
c1: 1.0
c2: 0.01
stochastic: True
load_model: False
load_model_path: ''

#run
reward_memory: 100
save_per_episodes: 2000

# network
policy: 'policy'
old_policy: 'old_policy'
n_layer_a_1: 20
n_layer_a_2: 20
n_layer_c_1: 20
n_layer_c_2: 20
temperature: 0.1

# output
SAVE_PATH: "model"
graph_path: "graph"
reward_output: "output"
output_filename: "out"
log: "log"